{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook acts as a guide\n",
    "\n",
    "The overall problem we are trying to solve is to take historical data about a project on github and use that to build a deep-learning model that can predict project activity in the future. We have broken the problem up into smaller steps, with each step producing some form of intermediate output that is saved to file.\n",
    "\n",
    "Each step is represented by a notebook. These are explained below. Note that all notebooks are found in the same directory as this one: /ideas-uo/machine_learning/predicting_project_activity.\n",
    "\n",
    "Also note that these steps assume that a single project has been selected to study. The project you select is a parameter to the various notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: wrangling (intake, inversion, compaction)\n",
    "\n",
    "Notebook: build_days_table.ipynb\n",
    "\n",
    "This notebook gets data into shape for feature set construction. It has 2 basic pieces. First, pull information from the github project into Python lists and dictionaries. The project info comes in organized by individual developers. Each developer has a list of commits he or she has carried out over the life of the project. The goal is to invert this structure. Pull out each individual commit as a row in a table. Iterating over the entire developer list, we will get all the commits on the project. Some further wrangling is done to build a table with interesting columns. The table is then reordered by date to get a chronological picture of commits in sequence. Converting this to a pandas table is then straightforward. The reordered table is written out as a csv file.\n",
    "\n",
    "The second piece is to compact the commits table to a day table. The final days table will have a summarized account (as columns) for each day in the project from begging until present.\n",
    "\n",
    "Here are screenshots of the 2 tables taken from the slack project.\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/j0wk6v3kn7bbyup/Screenshot%202019-07-14%2009.43.31.png?raw=1\">\n",
    "\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/k8tpjymolexlihj/Screenshot%202019-07-14%2010.26.48.png?raw=1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: create the feature set\n",
    "\n",
    "Notebook: build_feature_set.ipynb\n",
    "\n",
    "Given the table from step 1, first build a new table that is day-based: each row is a day where columns accumulate individual commits for the day. For days with no commit activity, produce rows with 0 accumulations. In particular, do not skip days.\n",
    "\n",
    "Once a day is compacted, build a feature for that day. A feature is a list of values. The simplest type of feature is one that takes values straight from the columns."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "get_commits.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
